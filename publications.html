<!DOCTYPE html>

<html lang="en" dir="ltr">
    
<head>
<title>fabiopoiesi | Publications</title>
<meta charset="iso-8859-1">
<link rel="stylesheet" href="styles/layout.css" type="text/css">
    
<!-- header to enable javascript -->
<script type="text/javascript" src="http://code.jquery.com/jquery-1.8.3.js"></script>


<script type='text/javascript'>
    $(function(){
      $('#disapp_menu u')
      .css({cursor: "pointer"})
      .on('click', function(){
          $(this).next('em').toggle();
          })
    });
</script>

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-58999519-1"></script>
<script>
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'UA-58999519-1');
</script>

</head>

<body>
<!----------------------------->
<!----------------------------->
<!----------------------------->
<div class="wrapper row1">
  <header id="header" class="clear">
    <div id="hgroup">
      <h1>Publications</h1>
    </div>
    <nav>
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="publications.html">Publications</a></li>
        <li><a href="presentations.html">Presentations</a></li>
        <li><a href="datasets.html">Datasets</a></li>
        <li class="last"><a href="about.html">About</a></li>
      </ul>
    </nav>
    <div class="clear"></div>
  </header>
</div>

<!----------------------------->
<!----------------------------->
<!----------------------------->
<!-- content -->
<div class="wrapper row2">
  <div id="container">

    <!----------------------------->
    <!----------------------------->
    <!-- content body -->
    <div id="content">
        <section>
            <p  align="justify"><em><font size="1">Copyright disclaimer: This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author's copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder.</font></em></p>
        </section>
      <!-- section 1 -->
      <section  class="last clear">


        <!----------------------------->
        <!--Journal papers-->
        <article>
          <h2>Journal papers</h2>
          <ul>
              <li><em>Point Clouds from Smartphones - Cheap and Rapid 3D Modelling</em><br>
                  E. Nocerino, F. Poiesi, F. Remondino, L. Van Gool<br>
                  GIM International, Mar 2018<br>
                  <div><a target="_blank" href=https://www.gim-international.com/content/article/point-clouds-from-smartphones>link</a>
                  </div>
              </li>
              <p style="margin:6px;">

              <li><em>Support Vector Motion Clustering</em><br>
                  I.A. Lawal, F. Poiesi, D. Anguita, A. Cavallaro<br>
                  IEEE Trans. on Circuits and Systems for Video Technology, vol. 27, no. 11, pp. 2395-2408, Nov 2017<br>
                  <div><a target="_blank" href="./files/papers/journals/2016_CSVT_SupportVectorMotionClustering_LawalPoiesiAnguitaCavallaro.pdf">pdf</a>, <a target="_blank" href="http://www.eecs.qmul.ac.uk/~andrea/svmc.html">website</a>
                  </div>
              </li>
              <p style="margin:6px;">

              <li><em>Tracking multiple high-density homogeneous targets</em><br>
                  F. Poiesi, A. Cavallaro<br>
                  IEEE Trans. on Circuits and Systems for Video Technology, vol. 25, no. 4, pp. 623-637, Apr 2015<br>
                  <div><a target="_blank" href="./files/papers/journals/2014_CSVT_TrackingMultiHDHTargets_Poiesi_Cavallaro.pdf">pdf</a>, <a target="_blank" href="https://www.youtube.com/watch?v=zNuabwxDBHk">video</a>, <a target="_blank" href="http://www.eecs.qmul.ac.uk/~andrea/thdt.html">website</a>
                  </div>
              </li>
              <p style="margin:6px;">
              
              <li><em>Predicting and recognizing human interactions in public spaces</em><br>
                  F. Poiesi, A. Cavallaro<br>
                  Journal of Real-Time Image Processing, Springer, vol. 10, no. 4, pp. 785-803, Dec 2015<br>
                  <div><a target="_blank" href="./files/papers/journals/2014_JRTIP_PredictingRecognizingInteractionsPublic_Poiesi_Cavallaro.pdf">pdf</a>
                  </div>
              </li>
              <p style="margin:6px;">
              
              <li><em>Measures of effective video tracking</em><br>
                  T. Nawaz, F. Poiesi, A. Cavallaro<br>
                  IEEE Trans. on Image Processing, vol. 23, no. 1, pp. 376-388, Jan 2014<br>
                  <div><a target="_blank" href="./files/papers/journals/2014_TIP_MultiTargetTrackingEvaluation_Tahir_Poiesi_Cavallaro.pdf">pdf</a>, <a target="_blank" href="https://www.youtube.com/watch?v=pp8HQEQ-INU">video</a>, <a target="_blank" href="http://www.eecs.qmul.ac.uk/~andrea/mtte.html">website</a>
                  </div>
              </li>
              <p style="margin:6px;">
              
              <li><em>Multi-target tracking on confidence maps: an application to people tracking</em><br>
                  F. Poiesi, R. Mazzon, A. Cavallaro<br>
                  Computer Vision and Image Understanding, Elsevier, vol. 117, no. 10, pp. 1257-1272, Oct 2013<br>
                  <div><a target="_blank" href="./files/papers/journals/2013_CVIU_MultiTargetTracking_Poiesi_Mazzon_Cavallaro.pdf">pdf</a>, <a target="_blank" href="https://www.youtube.com/watch?v=-4i0qg9DdGg">video</a>
                  </div>
              </li>
              
          </ul>
        </article>
        
        <!----------------------------->
        <!--Book chapters and magazines-->
        <article>
          <h2>Book chapters</h2>
          <ul>
              
              <li><em>Towards cognitive and perceptive video systems</em><br>
                  T. Akgun, C. Attwood, A. Cavallaro, C. Fabre, F. Poiesi, P. Szczuko<br>
                  Human Behaviour Understanding in Networked Sensing, Springer, Dec 2014<br>
                  <div><a target="_blank" href="./files/papers/book_chap/2014_HBU_TowardsCognitiveAndPerceptive_Akgun_Attwood_Cavallaro_Fabre_Poiesi_Szczuko.pdf">pdf</a>
                  </div>
              </li>
              <p style="margin:6px;">
              
              <li><em>Multi-target tracking in video</em><br>
                  F. Poiesi, A. Cavallaro<br>
                  Academic Press Library in Signal Processing: Volume 4, (Ed. S. Theodoridis), Elsevier, Sep 2013<br>
                  <div><a target="_blank" href="./files/papers/book_chap/2014_APLSP_MTT_in_video_Poiesi_Cavallaro.pdf">pdf</a>
                  </div>
              </li>
          </ul>
        </article>
        <!-- / articles -->
      
      <!----------------------------->
      <!--Conference papers-->
      <article>
          <h2>Conference papers</h2>
          <ul>
          <li><em>Seamless bare-hand interaction in Mixed Reality</em><br>
                  C. Battisti, S. Messelodi, F. Poiesi<br>
                  IEEE Proc. of Int'l Symposium on Mixed and Augmented Reality (ISMAR), Munich, DE, Oct 2018 (Poster)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2018_ISMAR_SeamlessBareHandInteractionMR_Battisti_Messelodi_Poiesi.pdf">pdf</a>, <a target="_blank" href="https://youtu.be/vRzYkzAq5xc">video</a>
          </li>
          <p style="margin:6px;">

          <li><em>A distributed vision-based consensus model for aerial-robotic teams</em><br>
                  F. Poiesi, A. Cavallaro<br>
                  IEEE Proc. of Intelligent Robots and Systems (IROS), Madrid, ES, Oct 2018 (Oral)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2018_IROS_DistributedVisionBasedConsensusAerialRoboticTeams_Poiesi_Cavallaro.pdf">pdf</a>
          </li>
          <p style="margin:6px;">

          <li><em>Distributed data exchange with Leap Motion</em><br>
                  M. Pani, F. Poiesi<br>
                  Int. Conference on Augmented Reality, Virtual Reality and Computer Graphics, Lecce, IT, Jun 2018 (Oral)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2018_SALENTOAVR_DistributedExchangeLeapMotion_Pani_Poiesi.pdf">pdf</a>, <a target="_blank" href="https://youtu.be/q7v7Y2auCag">video</a>
                  </div>
	        </li>
	        <p style="margin:6px;">

          	<li><em>3Dnow: image-based 3D reconstruction and modeling via web</em><br>
                  Y. Tefera, F. Poiesi, D. Morabito, F. Remondino, E. Nocerino, P. Chippendale<br>
                  Towards photogrammetry 2020, Trento, IT, Jun 2018 (Oral)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2018_TP2020_3dnowReconstructionWeb_Tefera_Poiesi_Morabito.pdf">pdf</a>
                  </div>
	        </li>
	        <p style="margin:6px;">

          <li><em>Cloud-based collaborative 3D reconstruction using smartphones</em><br>
                  F. Poiesi, A. Locher, P. Chippendale, E. Nocerino, F. Remondino, L. Van Gool<br>
                  European Conference on Visual Media Production (CVMP), London, UK, Dec 2017 (Oral)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2017_CVMP_CloudBasedCollaborativeReconstruction_Poiesi_Locher_Chippendale.pdf">pdf</a>, <a target="_blank" href="https://www.youtube.com/watch?v=bobWgdLtzIg">video</a>, <a target="_blank" href="https://tev.fbk.eu/technologies/collaborative-3d-reconstruction-with-smartphones">dataset</a>
                  </div>
              </li>
              <p style="margin:6px;">

          <li><em>Towards gesture-based multi-user interactions in collaborative virtual environments</em><br>
                  N. Pretto, F. Poiesi<br>
                  Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci., XLII-2-W8, 203-208, 2017 (Oral)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2017_LOWCOST3D_GestureBasedCollaborativeVR_Pretto_Poiesi.pdf">pdf</a>
                  </div>
              </li>
              <p style="margin:6px;">

          <li><em>3D Reconstruction with a collaborative approach based on smartphones and a cloud-based server</em><br>
                  E. Nocerino, F. Poiesi, A. Locher, Y.T. Tefera, F. Remondino, P. Chippendale, L. Van Gool<br>
                  Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci., XLII-2-W8, 187-194, 2017 (Oral)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2017_LOWCOST3D_CollaborativeApproachBasedOnSmartphons_Nocerino_Poiesi_Locher.pdf">pdf</a>
                  </div>
              </li>
              <p style="margin:6px;">

          <li><em>A Smartphone-based pipeline for the creative industry - The REPLICATE project</em><br>
                  E. Nocerino, F. Lago, D. Morabito, F. Remondino, L. Porzi, F. Poiesi, S. Rota Bulo', P. Chippendale, A. Locher, M. Havlena, L. Van Gool, M. Eder, A. Fotschl, A. Hilsmann, L. Kausch, P. Eisert<br>
                  Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci., XLII-2/W3, 535-541, 2017 (Oral)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2017_3DARCH_Smartphone3DpipelineREPLICATE.pdf">pdf</a>
                  </div>
              </li>
              <p style="margin:6px;">

          <li><em>Online multi-target tracking with strong and weak detections</em><br>
                  R. Sanchez Matilla, F. Poiesi, A. Cavallaro<br>
                  European Conference on Computer Vision (ECCV): Benchmarking Multi-target Tracking: MOTChallenge 2016, Amsterdam, NL, Oct 2016 (Oral)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2016_ECCVW_MultiTargetTrackingEarlyStrongDetections_Matilla_Poiesi_Cavallaro.pdf">pdf</a>
                  </div>
              </li>
              <p style="margin:6px;">
              <li><em>Detection of fast incoming objects with a moving camera</em><br>
                  F. Poiesi, A. Cavallaro<br>
                  British Machine Vision Conference (BMVC), York, UK, Sep 2016 (Oral)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2016_BMVC_DetectionFastIncomingObjects_Poiesi_Cavallaro.pdf">pdf</a>, <a target="_blank" href="https://drive.google.com/open?id=1hQrOpAORYs9I1eSFGu5VO7z_imNvmulV">source code</a>
                  </div>
              </li>
              <p style="margin:6px;">
              <li><em>Distributed vision-based flying cameras to film a moving target</em><br>
                  F. Poiesi, A. Cavallaro<br>
                  IEEE Proc. of Intelligent Robots and Systems (IROS), Hamburg, GE, Sep 2015 (Oral)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2015_IROS_DistributedFlyingCamerasFilmTarget_Poiesi_Cavallaro.pdf">pdf</a>, <a target="_blank" href="./files/presentations/presentation_iros_2015.pptx">slides</a>, <a target="_blank" href="https://www.youtube.com/watch?v=fyET9AwJQQM">video</a>
                  </div>
              </li>
              <p style="margin:6px;">
              <li><em>Self-positioning of a team of flying smart cameras</em><br>
                  F. Poiesi, A. Cavallaro<br>
                  IEEE Proc. of Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP), Singapore, Apr 2015 (Oral)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2015_ISSNIP_SelfPositioningTeamFlyingCameras_Poiesi_Cavallaro.pdf">pdf</a>, <a target="_blank" href="./files/presentations/presentation_issnip_2015.pdf">slides</a>, <a target="_blank" href="https://www.youtube.com/watch?v=D6ZX3czVTbk">video</a>
                  </div>
              </li>
              <p style="margin:6px;">

              <li><em>MTTV: an interactive trajectory visualization and analysis tool</em><br>
                  F. Poiesi, A. Cavallaro<br>
                  Proc. of Information Visualization Theory and Applications (IVAPP), Berlin, GE, Mar 2015 (Poster)<br>
                  <div><a target="_blank" href="http://www.eecs.qmul.ac.uk/~andrea/mttv.html">website</a>
                  </div>
              </li>
              <p style="margin:6px;">
              
              <li><em>Assessing tracking assessment measures</em><br>
                  T. Nawaz, F. Poiesi, A. Cavallaro<br>
                  IEEE Proc. of Image Processing (ICIP), Paris, FR, Oct 2014 (Poster)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2014_ICIP_AssessingTrackingMeasures_Nawaz_Poiesi_Cavallaro.pdf">pdf</a>, <a target="_blank" href="./files/presentations/poster_icip_2014.pdf">poster</a>
                  </div>
              </li>
              <p style="margin:6px;">

              <li><em>Detection and tracking of groups in crowd</em><br>
                  R. Mazzon, F. Poiesi, A. Cavallaro<br>
                  IEEE Proc. of Advanced Video and Signal-Based Surveillance (AVSS), Krakow, PL, Aug 2013 (Poster)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2013_AVSS_DetAndTrackGroupsInCrowd_Mazzon_Poiesi_Cavallaro.pdf">pdf</a>, <a target="_blank" href="./files/presentations/poster_avss_2013.pdf">poster</a>, <a target="_blank" href="https://www.youtube.com/watch?v=HDY44MLzRoA">video</a>
                  </div>
              </li>
              <p style="margin:6px;">
              
              <li><em>Detector-less ball localization using context and motion flow analysis</em><br>
                  F. Poiesi, F. Daniyal, A. Cavallaro<br>
                  IEEE Proc. of Image Processing (ICIP), Hong Kong, CN, Sep 2010 (Poster)<br>
                  <div><a target="_blank" href="./files/papers/conferences/2010_ICIP_DetectLessBall_Poiesi_Daniyal_Cavallaro.pdf">pdf</a>, <a target="_blank" href="https://www.youtube.com/watch?v=pckFacsIWg4">video</a>
                  </div>
              </li>
          </ul>
      </article>

      <!----------------------------->
      <!--Demos-->
      <article>
          <h2>Demos</h2>
          <ul>
          <li><em>3D reconstruction in your pocket</em><br>
                  F. Poiesi and P. Chippendale<br>
                  Mathematics for Computer Vision, Trento, IT, Feb 2018<br>
                  <a target="_blank" href="./files/papers/demos/2018_MCV_3DRecon_in_your_pocket_Poiesi_Chippendale.pdf">pdf</a>
          </li>
          <p style="margin:6px;">

          <li><em>REPLICATE project</em><br>
                  M. Galanti, A. Ragazzon, F. Poiesi, P. Chippendale<br>
                  EuroVR, Laval, FR, Dec 2017<br>
          </li>
          <p style="margin:6px;">

          <li><em>360-video authoring pipeline using user-generated 3D models</em><br>
                  F. Poiesi, P. Chippendale, J. Ceballos, R. Harris, E. Nocerino, F. Remondino<br>
                  European Conference on Visual Media Production (CVMP), London, UK, Dec 2017<br>
                  <a target="_blank" href="./files/papers/demos/2017_CVMP_360VideoAuthoringPipeline_Poiesi_Chippendale_Ceballos.pdf">pdf</a>
          </li>
          <p style="margin:6px;">

          <li><em>REPLICATE  project</em><br>
                  A. Foetschl, F. Poiesi, P.Chippendale<br>
                  AWE Europe, Munich, DE, Oct 2017<br>
          </li>
          <p style="margin:6px;">

          <li><em>Replicare in 3D</em><br>
                  F. Poiesi, E. Nocerino<br>
                  European Researchers' Night, Trento, IT, Sep 2017<br>
                  <a target="_blank" href="https://youtu.be/U5WCw72eq7k">video (local news - RTTR)</a>
          </li>
        </ul>
      </article>
      
      <!----------------------------->
      <!--Theses-->
      <article>
          <h2>Theses</h2>
          <ul>
              <li><em>Multi-target tracking and performance evaluation on videos</em><br>
                  F. Poiesi<br>
                  PhD Thesis, Queen Mary University of London, United Kingdom, Dec 2013<br>
                  <b>Advisor</b>: Prof. Andrea Cavallaro. <b>Examiners</b>: Dr. Krystian Mikolajczyk (University of Surrey, UK), Dr. Lewis Griffin (University College London, UK)<br>
                  <div id="disapp_menu"><u>Abstract</u><em> <font color="gray"> - Multi-target tracking is the process that allows the extraction of object motion patterns of interest from a scene. Motion patterns are often described through metadata representing object locations and shape information. In the first part of this thesis we discuss the state-of-the-art methods aimed at accomplishing this task on monocular views and also analyse the methods for evaluating their performance. The second part of the thesis describes our research contribution to these topics.<br>
                      We begin presenting a method for multi-target tracking based on track-before-detect (MT- TBD) formulated as a particle filter. The novelty involves the inclusion of the target identity (ID) into the particle state, which enables the algorithm to deal with an unknown and unlimited number of targets. We propose a probabilistic model of particle birth and death based on Markov Random Fields. This model allows us to overcome the problem of the mixing of IDs of close targets.<br>
                      We then propose three evaluation measures that take into account target-size variations, combine accuracy and cardinality errors, quantify long-term tracking accuracy at different accuracy levels, and evaluate ID changes relative to the duration of the track in which they occur. This set of measures does not require pre-setting of parameters and allows one to holistically evaluate tracking performance in an application-independent manner.<br>
                      Lastly, we present a framework for multi-target localisation applied on scenes with a high density of compact objects. Candidate target locations are initially generated by extracting object features from intensity maps using an iterative method based on a gradient-climbing technique and an isocontour slicing approach. A graph-based data association method for multi-target tracking is then applied to link valid candidate target locations over time and to discard those which are spurious. This method can deal with point targets having indistinguishable appearance and unpredictable motion.<br>
                      MT-TBD is evaluated and compared with state-of-the-art methods on real-world surveillance datasets (static and moving cameras) by using the proposed evaluation measures. In the case of online applications the inclusion of the ID in the particle state is effective, but it does not allow the proposed tracker to outperform offline trackers. The proposed measures are compared with existing measures for multi-target tracking and it is shown that the proposed ones comparatively maintain a reliable evaluation of the performance without prior knowledge about the application. The tracking of point targets in high-density scenes is evaluated on datasets containing insects and compared with MT-TBD and alternative multi-target trackers. The proposed solutions achieved the best results, especially in terms of ID maintenance on the targets</font></em>, <a target="_blank" href="https://qmro.qmul.ac.uk/jspui/handle/123456789/8848">pdf</a>
                  </div>
              </li>
              <p style="margin:6px;">
              <li><em>Motion-based ball localisation through motion flow analysis</em><br>
                  F. Poiesi<br>
                  MSc Thesis, Universita' degli studi di Brescia, Italy, Mar 2010<br>
                  <b>Advisor</b>: Prof. Riccardo Leonardi. <b>Co-advisor</b>: Prof. Andrea Cavallaro<br>
                  <div id="disapp_menu"><u>Abstract</u><em> <font color="gray"> - We present a technique for estimating the location of the ball during a basketball game without using a detector based on appearance features. The methods present in the state-of-the-art which aim to retrieve the ball, generally estimate the position of it using spatial features such as color, shape and size. Moreover, several approaches perform an additional temporal smoothing to filter out incorrect estimates. These methods are dependent upon the initial detection phase, which is based on the extraction of the visual features that not reliable because the ball is frequently occluded and similar to the background. Unlike existing approaches, instead of using visual features associated to the ball, we estimate the ball candidates based on the location of the players and their motion during attack actions. Hence, we propose an approach for ball localization that uses contextual information, i.e. players' bahavior, to estimate the approximate location of the ball. By this way this technique allows us to overcome the challenges due to frequent occlusions of the ball and its similarity in the appearance with the background. Based on this assumption, we use expected dynamics of the game and motion flow to estimate regions of the convergence of the players and the most probable region for the ball location. So, the most probable candidates for the ball location are extracted for each frame. Temporal consistency is then validated using the Kalman filter. Finally, we test the proposed approach on a real basketball scenario, where the ball is most of the time either partially of completely occluded. Experimental results show that the location of the ball can be estimated with an average accuracy of 82.6%</font></em>
                  </div>
              </li>
              <p style="margin:6px;">
              <li><em>Development of an application for the visualisation of dynamic video summaries</em><br>
                  F. Poiesi<br>
                  BSc Thesis, Universita' degli studi di Brescia, Italy, Nov 2007<br>
                  <b>Advisor</b>: Dr. Sergio Benini. <b>Co-advisor</b>: Dr. Pierangelo Migliorati
                  <div id="disapp_menu"><u>Abstract</u><em> <font color="gray"> - The large amount of multimedia content requires systems capable of automatically manage these data. Therefore, there is the necessity of summarising videos in order to quickly access to the desired content. There exist two methods for the automatic video summarisation. The first is a static summarsation, the second is a dynamic summarisation. The former uses key-frames, the latter uses short video clips (shots) to present the most informative content.<br>
                  In this thesis the summarisation is dynamic and assumed to be done upstream. We propose two systems for the generation of the output video. The first method is offline and can produce either high and low quality videos. High quality videos require a full re-encoding of the shots. The second method is online and is performed with Video Lan via Java interface.<br>
                  Experiments show that the offline process produces a more pleasant summary at a cost of a longer processing time.
                  </font></em>
                  </div>
              </li>
          </ul>
      </article>
      
      
      <!-- / articles -->
      </section>
      
    </div>
    
    <!----------------------------->
    <!----------------------------->
    <!-- right column -->
    <aside id="right_column">
    <h2 class="title">Highlights</h2>
    <table border="0">
      <tr>
        <td><div align="left"><iframe width="288" height="180" src="https://www.youtube.com/embed/CninjoIkz8w?rel=0&hd=1" frameborder="0" allowfullscreen></iframe></div>
        </td>
      </tr>
    </table>
    <p>&nbsp;</p>
    <table border="0">
      <tr>
        <td><div align="left"><iframe width="288" height="180" src="https://www.youtube.com/embed/fyET9AwJQQM?rel=0&hd=1" frameborder="0" allowfullscreen></iframe></div>
        </td>
      </tr>
    </table>
    <p>&nbsp;</p>
    <table border="0">
      <tr>
        <td><div align="left"><iframe width="288" height="180" src="https://www.youtube.com/embed/D6ZX3czVTbk?rel=0&hd=1" frameborder="0" allowfullscreen></iframe></div>
        </td>
      </tr>
    </table>
    <p>&nbsp;</p>
    <table border="0">
      <tr>
        <td><div align="left"><iframe width="288" height="180" src="https://www.youtube.com/embed/zNuabwxDBHk?rel=0&hd=1" frameborder="0" allowfullscreen></iframe></div>
        </td>
      </tr>
    </table>
    <p>&nbsp;</p>
    <table border="0">
      <tr>
        <td><div align="left"><iframe width="288" height="180" src="https://www.youtube.com/embed/-4i0qg9DdGg?rel=0&hd=1" frameborder="0" allowfullscreen></iframe></div>
        </td>
      </tr>
    </table>
    <p>&nbsp;</p>
    <table border="0">
      <tr>
        <td><div align="left"><iframe width="288" height="180" src="https://www.youtube.com/embed/pp8HQEQ-INU?rel=0&hd=1" frameborder="0" allowfullscreen></iframe></div>
        </td>
      </tr>
    </table>
    <p>&nbsp;</p>
    <table border="0">
      <tr>
        <td><div align="left"><iframe width="288" height="180" src="https://www.youtube.com/embed/HDY44MLzRoA?rel=0&hd=1" frameborder="0" allowfullscreen></iframe></div>
        </td>
      </tr>
    </table>
    <p>&nbsp;</p>
    <table border="0">
      <tr>
        <td><div align="left"><iframe width="288" height="180" src="https://www.youtube.com/embed/pckFacsIWg4?rel=0&hd=1" frameborder="0" allowfullscreen></iframe></div>
        </td>
      </tr>
    </table>
    </aside>
    <!----------------------------->
    <!----------------------------->
    
    <!-- / content body -->
    <div class="clear">
    </div>
  </div>
</div>

<!----------------------------->
<!----------------------------->
<!----------------------------->
<!-- footer -->
<div class="wrapper row3">
  <footer id="footer">
    <p class="fl_left">Copyright &copy; 2015 - All Rights Reserved - <a href="index.html">fabio-poiesi.com</a></p>
    <p class="fl_right">Thanks to <a href="http://www.os-templates.com/" title="Free Website Templates">OS Templates</a></p>
    <div class="clear">
    </div>
  </footer>
</div>
</body>

</html>
